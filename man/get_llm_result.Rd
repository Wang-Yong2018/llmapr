% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llmapi.R
\name{get_llm_result}
\alias{get_llm_result}
\title{Get LLM response by sent request support chat, image, and agent function.}
\usage{
get_llm_result(
  prompt = "hello,who are you",
  img_url = NULL,
  model_id = "llama",
  llm_type = "chat",
  history = NULL,
  funcs_json = NULL,
  timeout_seconds = api_timeout_seconds
)
}
\arguments{
\item{prompt, }{the user input of prompt. It should be prompt engineering based on feature type(chat, image, and
agent). It must be provided.}

\item{img_url, }{for image llm  type , it should be the image file path.}

\item{model_id, }{it is a model short name, for easy input, the inside function will convert it to full model name}

\item{llm_type, }{its should be one of item in the list c('chat','sql','answer','img_url','img','agent')
note:
chat: for normal large language chatting. It include history feature.
sql: for one time, text to sql feature. It convert natural language quesion to sql code
answer: for role based Q&A. It not full implemented yet.
img: for provide local image file path , for resize and encoding , sent to llm for analyzing. At
      present, only gemini, and gpt-4v support only
img_url mean remote image url . The img_url not support yet.
agent: for extract desired information from  user prompt  by predefined json template.}

\item{history, }{for llm type : chat, it is a list store previously chat between user and model}

\item{funcs_json, }{for llm type: agent, it is the list of json template for extract information.}

\item{timeout_seconds, }{for timeout settting purpose.}
}
\description{
Get LLM response by sent request support chat, image, and agent function.
}
\examples{
# example for chat

# example for image analyzing

# example for agent fucntion

# example for sql text 2 sql

}
